\documentclass[8pt,a4paper]{article}
\pagestyle{empty}
\usepackage{framed}
\usepackage{crlscode3e}

\begin{document}

\section*{Problems}

\begin{framed}
\textbf{\textit{2-1} Insertion sort on small arrays in merge sort}
\end{framed}

\subsubsection*{a}

The worst-case scenario for the insertion sort algorithm is $\Theta(n^{2})$.
Since each sublist has $k$ elements, sorting each one of them takes time
that is $\Theta(k^{2})$. However, all the sublists must be sorted and there
are $\frac{n}{k}$ of them, so sorting them all will take:

\begin{center}
\framebox{$\Theta(k^{2} . \frac{n}{k}) = \Theta(nk)$}
\end{center}

\subsubsection*{b}

We can use a Divide and Conquer approach to merge all the $\frac{n}{k}$ sublists.
We first merge the left $\frac{n}{2k}$ lists and then the right $\frac{n}{2k}$ lists.
To combine the results, the same $\proc{Merge}$ algorithm described in the book, that
is proven to be $\Theta(n)$. Thus, as there are $\frac{n}{k}$ sublists, the algorithm
will span $\lg (\frac{n}{k})$ recursive calls, yielding a complexity of:

\begin{center}
\framebox{$(cn . \lg (\frac{n}{k})) + cn = \Theta(n \lg (\frac{n}{k}))$}
\end{center}

\subsubsection*{c}

In order for the algorithm to have the same running time of the standard merge sort,
its running time must be $\Theta(n \lg n)$. Performing some manipulations on the
new algorithm complexity:

\begin{center}
$nk + n \lg (\frac{n}{k}) =$ \\
$nk + n(\lg n - \lg k) =$ \\
$nk + n \lg n - n \lg k$
\end{center}

Thus, in order for the above function to be $\Theta(n \lg n)$, the highest order
member of it must be $n \lg n$, that is:

\begin{center}
$nk \leq n \lg n \Rightarrow$
\framebox{$k \leq \lg n$}
\end{center}

The maximum value for $k$ is $\lg n$.

\subsubsection*{d}

In practice, the value of $k$ should be chosen for inputs of size for which
the running time of insertion sort is smaller than that of merge sort, considering
constant factors.

\newpage

\begin{framed}
  \textbf{\textit{2-2} Correctness of bubblesort}
\end{framed}

\subsubsection*{a}

Besides the order property already presented in the exercise, the every element in $A$
must also be present in $A'$, that is:

\begin{center}
  $A'[i] \subset A \forall i \in \{ 1 \twodots n \}$
\end{center}

\subsubsection*{b}

The loop invariant of the inner loop of the $\proc{Bubble-Sort}$ algorithm is:

\begin{quotation}
  At the start of each iteration of the inner \For loop, the smallest element of
  $A[j \twodots n]$ is at position $j$.
\end{quotation}

Let's analyze this invariant: \\

\textbf{Initialization}: the loop starts with $j = \attrib{A}{length} = n$, and the
invariant is trivially correct. \\

\textbf{Maintenance}: at each iteration of the loop, the algorithm checks whether the
element of position $j$ is smaller than then one at position $j - 1$ and swaps them
so that the smaller one is placed before the other. Thus, $j$ will always be the index
of the smaller checked element in the array. \\

\textbf{Termination}: the loop terminates when $j = i$. In this condition, $A[i]$ will
contain the smallest element from in $A[i \twodots n]$.

\subsubsection*{c}

The invariant of the outer loop of the $\proc{Bubble-Sort}$ algorithm can be stated as:

\begin{quotation}
  At the start of each iteration of the outer \For loop, the subarray $A[1 \twodots i]$
  is sorted.
\end{quotation}

Analyzing the loop invariant: \\

\textbf{Initialization}: the loop starts with $i = 1$. An array with only one element
is trivially sorted, so the invariant holds on initialization. \\

\textbf{Maintenance}: as shown in the previous exercise, the inner loop guarantees
that after it is done, the smallest element from $A[i \twodots n]$ will be at position
$i$. Thus, the array gets incrementally sorted and $A[1 \twodots i]$ is sorted after
every iteration. \\

\textbf{Termination}: The loop terminates when $i = \attrib{A}{length}$. When this
happens, the array from $A[1 \twodots n]$ is sorted, that is, the whole array is
sorted. Hence, the algorithm is correct.

\subsubsection*{d}

No matter the disposition of the input array, the $\proc{Bubble-Sort}$ algorithm
always loops twice in it, and thus have a running time of $\Theta(n^{2})$, same
as the worst-case for insertion sort.

\begin{framed}
  \textbf{\textit{2-3} Correctness of Horner's rule}
\end{framed}

\subsubsection*{a}

The main loop of the algorithm runs $n + 1$ times. Thus, its running time
is $\Theta(n)$.

\subsubsection*{b}

The naive polinomial-evaluation algorithm would be the following:

\begin{codebox}
  \Procname{$\proc{Naive-Polinomial}(A, x)$}
  \li $sum = 0$
  \li \For $j = 1 \To \attrib{A}{length}$
        \Do
  \li     $sum = sum + A[j] . exp(x, j)$
        \End
\end{codebox}

Assuming that exponentiation is not a basic operation (only multiplication is),
it would need to be calculated in each step, taking time that is $\Theta(\lg n)$.
As the loop runs $n$ times, the whole algorithm running time is $\Theta(n \lg n)$.

\subsubsection*{c}

\textbf{Initialization}: The loop starts with $i = n$. In this case, the summation
goes from $k = 0$ to $n - (i + 1) = -1$, that is, an empty sum. So, the $y = 0$,
and the invariant holds. \\

\textbf{Maintenance}: at each iteration, $y$ is calculated as $a_i$ plus $x$
multiplied with the previous value of $y$:

\begin{center}
  $y = a_i + x . y \Rightarrow$ \\
  $y = a_i + x (\sum\limits_{k = 0}^{n-(i+1)} a_{k+i+1} x^k) \Rightarrow$ \\
  $y = a_i + \sum\limits_{k = 1}^{n - i} a_{k+i} x^k \Rightarrow$ \\
  $y = \sum\limits_{k = 0}^{n-i} a_{k+i} x^k$
\end{center}

Thus, the invariant holds on iterations. \\

\textbf{Termination}: The loop terminates when $i = -1$. In this scenario, we have:

\begin{center}
  $y = \sum_{k = 0}^{n} a_k x^k \Rightarrow$
  \framebox{$y = P(x)$}
\end{center}

and the algorithm is correct.

\subsubsection*{d}

As we saw above, the algorithm is correct.


\end{document}
